{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c73dfc8c-c102-4fd8-8a93-52000b6e5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71e23c33-b5ba-4ae8-9b34-47da38f1ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stemmer = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cdb4c85f-91e9-4c18-b87a-16fd10c86c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "        return data['text'], data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2fc2c003-2146-4c94-b439-4635b5c28e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text: str) -> dict:\n",
    "    \"\"\"For a given text returns bag of words (a dict)\"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    words = [w for w in words if len(w)>2]\n",
    "\n",
    "    return dict(Counter(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa55895a-73cf-4f31-a3eb-411bb559d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tbd_matrix(docs: list[dict]) -> sparse.coo_array: \n",
    "    \"\"\"Given bags of words (dicts) return term by document matrix.\"\"\"\n",
    "    terms = {}\n",
    "    row  = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for doc_index, doc in enumerate(docs):\n",
    "        for term, count in doc.items():\n",
    "            term_index = terms.setdefault(term, len(terms))\n",
    "            row.append(term_index)\n",
    "            col.append(doc_index)\n",
    "            data.append(count)\n",
    "\n",
    "    return sparse.coo_array((data, (row, col)), shape=(len(terms), len(docs))), terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3e7520b6-767a-45cf-a70c-5466d270454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_by_idf(matrix) -> sparse.coo_array:\n",
    "    \"\"\"Multiplies given matrix by idf vector.\"\"\"\n",
    "    idf = np.log(matrix.shape[1]/(matrix>0).sum(axis=1))\n",
    "    return matrix.multiply(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d7743c7-1e4a-4c84-895d-ad4dbae82d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col(matrix) -> sparse.coo_array:\n",
    "    \"\"\"Normalizes columns so that each feature col has equal l2 norm.\"\"\"\n",
    "    return matrix.multiply(1/sparse.linalg.norm(matrix, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c981406-4e7c-4b6e-bcdd-58e2e2e6591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(**kwargs):\n",
    "    \"\"\"Saves things using pickle.\"\"\"\n",
    "    \n",
    "    if \"tbd_matrix\" in kwargs:\n",
    "        matrix = kwargs[\"tbd_matrix\"].tocsr()\n",
    "        sparse.save_npz('tbd_matrix.npz', matrix)\n",
    "    for name, thing in kwargs.items():\n",
    "        with open(f'{name}.pickle', \"wb\") as f:\n",
    "            pickle.dump(thing, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4ae9dddf-4bbf-4d08-97b8-8ea78f533ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(*args):\n",
    "    \"\"\"Loads things from pickle files.\"\"\"\n",
    "    loaded = []\n",
    "    for name in args:\n",
    "        with open(f'{name}.pickle', \"rb\") as f:\n",
    "            loaded.append( pickle.load(f))\n",
    "        \n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a624c-2008-44c6-b937-c83247f13e4f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91deb1c5-af52-4348-a151-8ae0e359505c",
   "metadata": {
    "tags": [
     "tgg"
    ]
   },
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c878588f-7114-4c68-a73a-c8a0f6224cc5",
   "metadata": {
    "tags": [
     "tgg"
    ]
   },
   "outputs": [],
   "source": [
    "def processed_docs(n):\n",
    "    filenames = Path(\"PlainTextWikipedia\\data\").glob('*')\n",
    "    i = 0\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            txt = read_file(filename)\n",
    "        except Exception as e:\n",
    "            print(\"Problem with reading file: \", e)\n",
    "            continue\n",
    "        try:\n",
    "            file = process_text(txt)\n",
    "        except Exception as e:\n",
    "            print(\"Problem with reading file: \", e)\n",
    "            continue\n",
    "        yield file\n",
    "        i+=1\n",
    "        if i>=n:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b1cc4e0-e1f8-47dc-b837-22036d515a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(processed_docs(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "afceb994-36fb-4722-b8b6-6308a3aa90cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [232]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m tbd_matrix, terms \u001b[38;5;241m=\u001b[39m build_tbd_matrix(docs)\n\u001b[1;32m----> 2\u001b[0m tbd_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmul_by_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtbd_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m tbd_matrix \u001b[38;5;241m=\u001b[39m normalize_col(tbd_matrix)\n\u001b[0;32m      4\u001b[0m save(tbd_matrix, terms)\n",
      "Input \u001b[1;32mIn [139]\u001b[0m, in \u001b[0;36mmul_by_idf\u001b[1;34m(matrix)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Multiplies given matrix by idf vector.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m idf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m(matrix\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43midf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:390\u001b[0m, in \u001b[0;36mspmatrix.multiply\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultiply\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;124;03m\"\"\"Point-wise multiplication by another matrix\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtocsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\sparse\\_compressed.py:472\u001b[0m, in \u001b[0;36m_cs_matrix.multiply\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    470\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(ret\u001b[38;5;241m.\u001b[39mdata, other[ret\u001b[38;5;241m.\u001b[39mrow]\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    473\u001b[0m ret\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39mndarray)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mValueError\u001b[0m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "tbd_matrix, terms = build_tbd_matrix(docs)\n",
    "tbd_matrix = mul_by_idf(tbd_matrix)\n",
    "tbd_matrix = normalize_col(tbd_matrix)\n",
    "save(tbd_matrix, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35f8b5b3-bd64-4647-a680-f8ee891a1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, t = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e845-da52-42a5-b673-fe62991b08d0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d4b245ce-a4f9-4511-8614-84ad088c551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_matrix_approx(matrix, k):\n",
    "    \"\"\"svd\"\"\"\n",
    "    svd = TruncatedSVD(n_components=k).fit(matrix.T)\n",
    "    low_rank_matrix = svd.transform(matrix.T)\n",
    "    return low_rank_matrix.T, svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e917e-d5fc-474a-8bc1-fb0be4fd7f72",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f42ea-4996-4982-b22c-08fb3beac3f9",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "72619020-8f54-40b4-92c1-ff7371bca2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_text_to_vector(txt, terms) -> sparse.coo_array:\n",
    "    words = process_text(txt).keys()\n",
    "    cords = [terms[w] for w in words if w in terms] \n",
    "    query_vector = sparse.coo_array( \n",
    "            ([1]*len(cords), (cords, [0]*len(cords))), \n",
    "            shape=(len(terms), 1)\n",
    "        )\n",
    "    query_vector = query_vector/sparse.linalg.norm(query_vector)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4f9e511e-4cca-4a3b-852a-7dda800f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(matrix, query_vector, svd=None):\n",
    "    query_vector = query_vector.todense()\n",
    "    if svd:\n",
    "        query_vector = svd.transform(query_vector.T).T\n",
    "    similarities = query_vector.T @ matrix\n",
    "    k\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8dc41ff2-1dab-4735-83cb-da8983159660",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = query_text_to_vector(\"hi this is unfortunate air force one\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533e33e-09b9-4724-8a78-57efc674944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4c21c950-97fa-4e2d-a4a2-4f1b2d30518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(matrix, k):\n",
    "    \"\"\"svd\"\"\"\n",
    "    return sparse.linalg.svds(matrix.T, k=k)\n",
    "\n",
    "\n",
    "def lower_rank(svd, k):\n",
    "    \"\"\"Lower rank matrix approximation.\"\"\"\n",
    "    u, s, vt = svd\n",
    "    return u[:, :k] @ np.diag(s[:k]) @ vt[:k, :]\n",
    "\n",
    "\n",
    "def svd_transform_vector(vector, svd, k):\n",
    "    \"\"\"Svd transform vector.\"\"\"\n",
    "    u, s, vt = svd\n",
    "    return vt[:k, :] @ vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "815e4580-f6b7-4b94-9023-7bec50fa368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = svd(m, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f1e76125-bf30-44cb-ae0d-2faaa9b110d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2285)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_rank(svd,10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dd7e9-33ef-4838-b917-6523d289584d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3ea50-3d9f-4bff-ad15-84f06a7ed0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
